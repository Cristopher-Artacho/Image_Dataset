{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "from keras import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import inception_v3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['CUP', 'SPOON', 'FORK', 'MOUSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CAMERA = cv2.VideoCapture(0)\n",
    "camera_height = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_frames_type_1 = [ ]\n",
    "raw_frames_type_2 = [ ]\n",
    "raw_frames_type_3 = [ ]\n",
    "raw_frames_type_4 = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while CAMERA.isOpened():\n",
    "    #read a new camera frame\n",
    "\n",
    "    ret, frame = CAMERA.read()\n",
    "\n",
    "    #Flip\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    #Rescale the images output\n",
    "\n",
    "    aspect = frame.shape[1]/float (frame.shape[0])\n",
    "    res = int(aspect * camera_height)\n",
    "    frame = cv2.resize(frame, (res, camera_height))\n",
    "\n",
    "    #the green rectangle frame\n",
    "    cv2.rectangle(frame, (300, 75), (650, 425), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow (\"Capturing\", frame)\n",
    "\n",
    "    #controls q = quit / s = capturing\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key & 0xff == ord ('q'):\n",
    "        break\n",
    "    elif key & 0xff == ord ('1'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_1.append(frame)\n",
    "    elif key & 0xff == ord ('2'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_2.append(frame)\n",
    "    elif key & 0xff == ord ('3'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_3.append(frame)\n",
    "    elif key & 0xff == ord ('4'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_4.append(frame)\n",
    "\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "\n",
    "#camera\n",
    "CAMERA.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_width = 339\n",
    "save_height = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retval = os.getcwd()\n",
    "print (\"Currently Working Directory %s\" % retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the dataset\n",
    "print ('img1:', len(raw_frames_type_1))\n",
    "print ('img2:', len(raw_frames_type_2))\n",
    "print ('img3:', len(raw_frames_type_3))\n",
    "print ('img4:', len(raw_frames_type_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#crop the images\n",
    "\n",
    "#for frames type 1\n",
    "for i, frame in enumerate (raw_frames_type_1):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_1/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for frames type 2\n",
    "for i, frame in enumerate (raw_frames_type_2):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_2/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for frames type 3\n",
    "for i, frame in enumerate (raw_frames_type_3):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_3/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for frames type 4\n",
    "for i, frame in enumerate (raw_frames_type_4):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_4/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 96\n",
    "height = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_type_1 = [ ]\n",
    "images_type_2 = [ ]\n",
    "images_type_3 = [ ]\n",
    "images_type_4 = [ ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in glob('img_1/*.*'):\n",
    "    image = preprocessing.image.load_img(image_path, target_size = (width, height))\n",
    "    x = preprocessing.image.img_to_array(image)\n",
    "\n",
    "    images_type_1.append(x)\n",
    "    \n",
    "for image_path in glob('img_2/*.*'):\n",
    "    image = preprocessing.image.load_img(image_path, target_size = (width, height))\n",
    "    x = preprocessing.image.img_to_array(image)\n",
    "\n",
    "    images_type_2.append(x)\n",
    "    \n",
    "for image_path in glob('img_3/*.*'):\n",
    "    image = preprocessing.image.load_img(image_path, target_size = (width, height))\n",
    "    x = preprocessing.image.img_to_array(image)\n",
    "\n",
    "    images_type_3.append(3)\n",
    "    \n",
    "for image_path in glob('img_4/*.*'):\n",
    "    image = preprocessing.image.load_img(image_path, target_size = (width, height))\n",
    "    x = preprocessing.image.img_to_array(image)\n",
    "\n",
    "    images_type_4.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "\n",
    "for i, x in enumerate(images_type_1[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = preprocessing.image.array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, x in enumerate(images_type_2[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = preprocessing.image.array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[0]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(images_type_3[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = preprocessing.image.array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[0]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(images_type_4[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = preprocessing.image.array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#prepare image to tensor\n",
    "\n",
    "\n",
    "X_type_1 = np.array(images_type_1)\n",
    "X_type_2 = np.array(images_type_2)\n",
    "X_type_3 = np.array(images_type_3)\n",
    "X_type_4 = np.array(images_type_4)\n",
    "\n",
    "#check the shape using .shape() check the images count\n",
    "\n",
    "print (X_type_1.shape)\n",
    "print (X_type_2.shape)\n",
    "print (X_type_3.shape)\n",
    "print (X_type_4.shape)\n",
    "\n",
    "(13, 96, 96, 3)\n",
    "(23, 96, 96, 3)\n",
    "(14, 96, 96, 3)\n",
    "(22, 96, 96, 3)\n",
    "\n",
    "X_type_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.concatenate(X_type_1, X_type_2, axis= 0)\n",
    "\n",
    "if len(X_type_3):\n",
    "    X = np.concatenate((X, X_type_3), axis= 0)\n",
    "if len (X_type_4):\n",
    "    X = np.concatenate((X, X_type_3), axis= 0)\n",
    "\n",
    "    X = X/250\n",
    "\n",
    "    X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_type_1 = [0 for item in enumerate(X_type_1)]\n",
    "y_type_2 = [0 for item in enumerate(X_type_2)]\n",
    "y_type_3 = [0 for item in enumerate(X_type_3)]\n",
    "y_type_4 = [0 for item in enumerate(X_type_4)]\n",
    "\n",
    "y = np.concatenate((y_type_1, y_type_2), axis= 0)\n",
    "\n",
    "if len(y_type_3):\n",
    "    y = np.concatenate((y, y_type_3), axis= 0)\n",
    "if len(y_type_4):\n",
    "    y = np.concatenate((y, y_type_4), axis= 0)\n",
    "\n",
    "y = to_categorical (y, num_classes=len(class_names))\n",
    "\n",
    "\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default parameters\n",
    "\n",
    "#situational - values, you may not adjust here\n",
    "\n",
    "conv_1 = 16\n",
    "conv_1_drop = 0.2\n",
    "conv_2 = 32\n",
    "conv_2_drop = 0.2\n",
    "dense_1_n = 1024\n",
    "dense_1_drop = 0.2\n",
    "dense_2_n = 512\n",
    "dense_2_drop = 0.2\n",
    "\n",
    "#values you can adjust\n",
    "lr = 0.001\n",
    "epochs = 5\n",
    "batch_size = 10\n",
    "color_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(conv_1_drop = conv_1_drop, conv_2_drop = conv_2_drop,\n",
    "                dense_1_n = dense_1_n, dense_1_drop = dense_1_drop,\n",
    "                dense_2_n = dense_2_n, dense_2_drop = dense_2_drop, lr = lr):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(conv_1, (3,3),\n",
    "                            input_shape = (width, height, color_channels),\n",
    "                            activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(conv_1_drop))\n",
    "    \n",
    "    #---\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #---\n",
    "    model.add(Dense(dense_1_n, activation='relu'))\n",
    "    model.add(Dropout(dense_1_drop))\n",
    "\n",
    "    #---\n",
    "    model.add(Dense(dense_2_n, activation= 'relu'))\n",
    "    model.add(Dropout(dense_2_drop))\n",
    "\n",
    "    #---\n",
    "    model.add(Dense(len(class_names), activation= 'relu'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                optimizer= Adam(clipvalue = 0.5),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #model parameter\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #do not run yet\n",
    "\n",
    "history = model.fit(X, y, validation_split = 0.10, epochs = 10, batch_size = 5)\n",
    "\n",
    "print (history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Model Evaluation\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %.2f%%' % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss and Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['Accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "\n",
    "def plt_show(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cup = 'img_1/10.png'\n",
    "spoon = 'img_2/10.png'\n",
    "fork = 'img_3/10.png'\n",
    "mouse = 'img_4/10.png'\n",
    "\n",
    "imgs = [cup, spoon, fork, mouse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def predict_(_img_path):\n",
    "classes = None\n",
    "predicted_classes = [ ]\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    type_ = preprocessing.image.load_img(imgs[i], target_size=(width, height))\n",
    "    plt.imshow(type_)\n",
    "    plt.show()\n",
    "\n",
    "    type_x = np.expand_dims(type_, axis=0)\n",
    "    prediction = model.predict(type_x)\n",
    "    index = np.argmax(prediction)\n",
    "    print(class_names[index])\n",
    "    classes = class_names[index]\n",
    "    predicted_classes.append(class_names[index])\n",
    "\n",
    "cm = confusion_matrix(class_names, predicted_classes)\n",
    "f = sns.heatmap(cm, xticklabels=class_names, yticklabels=predicted_classes, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_1 = preprocessing.image.load_img('img_1/10.png', target_size=(width, height))\n",
    "\n",
    "plt.imshow(type_1)\n",
    "plt.show()\n",
    "\n",
    "type_1_x = np.expand_dims(type_1, axis=0)\n",
    "prediction = model.predict(type_1_x)\n",
    "index = np.argmax(prediction)\n",
    "\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_2 = preprocessing.image.load_img('img_2/10', target_size=(width, height)) #Need further checking\n",
    "\n",
    "plt.imshow(type_2)\n",
    "plt.show()\n",
    "\n",
    "type_2_x = np.expand_dims(type_2, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_3 = preprocessing.image.load_img('img_3/10', target_size=(width, height)) #Need further checking\n",
    "\n",
    "plt.imshow(type_3)\n",
    "plt.show()\n",
    "\n",
    "type_3_x = np.expand_dims(type_3, axis=0)\n",
    "\n",
    "prediction = model.predict(type_3_x)\n",
    "                           \n",
    "index = np.argmax(prediction)\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "type_4 = preprocessing.image.load_img('img_4/10', target_size=(width, height)) #Need further checking\n",
    "\n",
    "plt.imshow(type_4)\n",
    "plt.show()\n",
    "\n",
    "type_4_x = np.expand_dims(type_4, axis=0)\n",
    "\n",
    "prediction = model.predict(type_4_x)\n",
    "                           \n",
    "index = np.argmax(prediction)\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction = model.predict(type_2_x)\n",
    "                           \n",
    "index = np.argmax(prediction)\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live predictions using camera\n",
    "\n",
    "import time\n",
    "CAMERA = cv2.VideoCapture(0)\n",
    "camera_height = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    _, frame = CAMERA.read()\n",
    "\n",
    "    #flip \n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    #rescale the images output\n",
    "    aspect = frame.shape[1]/ float(frame.shape(0))\n",
    "    res = int(aspect* camera_height)\n",
    "    frame = cv2.resize(frame, (res, camera_height))\n",
    "\n",
    "    #get roi \n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse the roi\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #adjust alignment\n",
    "    roi = cv2.resize(roi, (width, height))\n",
    "    roi_x = np.expand_dims(roi, axis=0)\n",
    "    predictions = model.predict(roi_x)\n",
    "    type_1_x, type_2_x, type_3_x, type_4_x = predictions[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(frame, (300, 75), (650, 425), (240, 100, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions /labels\n",
    "\n",
    "tipe_1_txt = '{} - {}%'.format(class_names[0], int(type_1_x*100))\n",
    "cv2.putText(frame, tipe_1_txt, (70,210), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "tipe_2_txt ='{} - {}%'.format(class_names[1], int(type_2_x*100))\n",
    "cv2.putText(frame, tipe_2_txt, (70,235), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "tipe_3_txt ='{} - {}%'.format(class_names[2], int(type_3_x*100))\n",
    "cv2.putText(frame, tipe_3_txt, (70,255), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "tipe_4_txt ='{} - {}%'.format(class_names[3], int(type_4_x*100))\n",
    "cv2.putText(frame, tipe_4_txt, (70,275), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "cv.imshow(\"Real time object detection\", frame)\n",
    "\n",
    "#Controls q = quit/s = capturing \n",
    "key = cv2.waitKey(1)\n",
    "\n",
    "if key & 0xff == ord('q'):\n",
    "    break #debug nlang ninyo dri. wla sya ga break. ang loop is ang while(True) sa babaw\n",
    "\n",
    "#preview\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMERA.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
